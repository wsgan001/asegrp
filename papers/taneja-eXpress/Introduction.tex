
\section{Introduction}
\label{sec:intro}
Regression test generation aims at generating a test suite that can detect behavioral differences between the original and the new versions of a program. A behavioral difference between two versions of a program can be reflected by the difference between the observable outputs produced by the execution of the same test (referred to as a difference-exposing test) on the two versions. Developers can inspect these behavioral differences to determine whether they are intended or unintended (i.e., regression faults).

Regression test generation can be automated by using Dynamic Symbolic
Execution (DSE)~\cite{dart, cute, exe}, a state-of-the-art test generation
technique, to generate a test suite achieving high
structural coverage. DSE explores paths in a program to
achieve high structural coverage, and exploration of all
these paths can often be expensive. However, if our aim is
to detect behavioral differences between two versions of a
program, we do not need to explore all these paths in the program
since not all these paths are relevant for detecting behavioral
differences.

To formally investigate irrelevant paths for exposing behavioral differences, we adopt the 
Propagation, Infection, and Execution (PIE) model~\cite{voas} of error propagation. According to the PIE model, a fault can be detected by a test if a faulty statement is executed (E), the execution of the faulty statement infects the state (I), and the infected state (i.e., error) propagates to an observable output (P). A change in the new version of a program can be treated as a fault and then the PIE model is applicable for effect propagation of the change. Many paths in a program often cannot help in satisfying any of the conditions P, I, or E of the PIE model. 

In this paper, we present an approach{\footnote{\scriptsize{An earlier version of this work~\cite{taneja09:guided} is described in a four-page paper that appears in the NIER track of ICSE 2009. This
version significantly extends the previous work in the following major ways.
First, in this paper, we develop techniques for efficiently finding irrelevant branches 
that cannot execute any change. 
Second, we develop techniques for exploiting the existing test suite for efficiently generating regression tests.
Third, we automate our approach by developing a tool.
Fourth, we conduct extensive experiments to evaluate our approach.}} \CodeIn{eXpress} and its implementations that uses DSE to detect behavioral differences based on the notion of the PIE model.

Our approach first determines all the branches (in the program under test) that cannot help in achieving any of the conditions E and I of the PIE model in terms of the changes in the program. To make test generation efficient, we develop a new search strategy for DSE to avoid exploring these irrelevant branches (including which can lead to an irrelevant path\footnote{\scriptsize{An irrelevant path is a path that cannot help in achieving P, I, and E of the PIE model.}}). In particular, our approach guides DSE to avoid from flipping branching nodes\footnote{\scriptsize{A branching node in the execution tree of a program is an instance of a conditional statement in the source code. A branching node consists of two sides (or more than two sides for a \CodeIn{switch} statement): the true branch and the false branch. Flipping a branching node is flipping the execution of the program from the true (or false) branch of the branching node to the false (or true) branch. Flipping a branching node representing a switch statement is flipping the execution of the current branch to another unexplored branch.}}, which on flipping execute some irrelevant branch. 

In addition, our approach can exploit the existing test suite (if available) for the original version by seeding the tests in the test suite to the program exploration. Our technique of seeding the exploration with the existing test suite can be used to efficiently augment an existing test suite so that various changed parts of the program (that are not covered by the existing test suite) are covered by the augmented test suite. 

\Comment{In addition, our approach prioritizes the flipping of branching nodes\footnote{A branching node in the execution tree of a program is an instance of a conditional statement in the source code. A branching node consists of two sides (or more than two sides for a \CodeIn{switch} statement): the true branch and the false branch. Flipping a branching node is flipping the execution of the program from the true (or false) branch of the branching node to the false (or true) branch.  Flipping a branching node representing a switch statement is flipping the execution of current branch to some unexplored branch.} in such a manner that behavioral differences are more likely to be detected earlier in path exploration.
}

This paper makes the following major contributions:
\\ \textbf{Path Exploration for Regression Test Generation.} We propose an approach called \CodeIn{eXpress} that uses DSE for efficient generation of regression unit tests. To the best
of our knowledge, ours is the first approach that guides path exploration on the new version specifically for regression test generation.
\\ \textbf{Incremental Exploration.} We develop a technique for exploiting an existing test suite, so that path exploration focuses on covering the changes rather than starting from scratch. To the best of our knowledge, ours is the first technique that leverages an existing test suite for automated regression test generation.
\\ \textbf{Implementation.} We have implemented our \CodeIn{eXpress} approach in a tool as an extension for Pex~\cite{Pex},  an automated structural testing tool for .NET developed at Microsoft Research. Pex has been previously used internally at Microsoft to test core components of the .NET architecture and has found serious
bugs~\cite{Pex}. The current Pex has been downloaded for thousands of times in industry. 
\\ \textbf{Evaluation.} We have conducted experiments on 72 versions (in total) of four programs. Experimental results show that our approach requires about 53\% fewer runs (i.e., explored paths) on average to cause the execution of a changed region and 44\% fewer to cause program-state differences after its execution than exploration without guidance. In addition, our approach requires 71\% fewer runs to cover all the changed regions (i.e, infection) by exploiting an existing test suite than exploration without using the test suite. 
%\end{itemize}
\Comment{
The rest of the paper is organized as follows. Section~\ref{sec:example} 
presents an example to illustrate our approach. Section~\ref{sec:approach} presents 
our approach and the major components involved in the approach. Section~\ref{sec:evaluation}
presents the evaluation results. Section~\ref{sec:validity} discusses the threats to validity of the evaluation results. Section~\ref{sec:related} discusses related
work. Section~\ref{sec:discussion} discusses research issues and future work,
and Section~\ref{sec:conclusion} concludes.
}