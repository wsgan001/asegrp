\section{Discussion} 
\label{sec:limitations}

In our results related to test-code maintenance, there is a scenario where the number of PUTs is more than the number of CUTs. The reason is that it is sometimes difficult to generalize test oracles in a few cases. For example, consider the following CUT:\vspace*{-1.5ex}

\begin{CodeOut}
\begin{alltt}
public void Canonicalize() \{
\hspace*{0.1in}PexAssert.AreEqual(@"C:/folder1/file.tmp",
\hspace*{0.3in}PathUtils.Canonicalize(@"C:/folder1/./folder2/
\hspace*{0.3in}../file.tmp")); 
\}
\end{alltt}
\end{CodeOut} \vspace*{-1.5ex}

\noindent The \CodeIn{Canonicalize} method in \CodeIn{PathUtils} accepts a \CodeIn{string} parameter and uses a complex procedure to transform the input into a standard form. It is easy to identify the expected output for concrete strings such as \CodeIn{C:/folder1/.../folder2/.../file.tmp}. However, when the CUT is generalized with a parameter for the input string, it is challenging to identify the expected output. Although a developer can use our commutative diagram pattern and provide an alternative implementation for the \CodeIn{Canonicalize} method, the amount of required effort could be higher than the effort required to write the implementation of the actual method under test. To address this issue in our empirical study, we split the CUT into multiple PUTs during test generalization. For those PUTs with difficulties in generalizing test oracles, we do not generalize the test assertions, and instead replace assertions with statements that print outputs suitable for manual review, i.e., use the \emph{manual output review} pattern in our proposed patterns. These PUTs can still help in detecting defects related to exceptions.

In our empirical study, for a PUT generalized from the CUT \CodeIn{GraphWithSelfEdges} (in the \CodeIn{Concepts} namespace of QuickGraph), we identify that the PUT achieved branch coverage of 70\%, which is less than the coverage achieved by the existing CUT. The reason is that the transformed PUT executes a huge amount of code and Pex reached the upper-bound of the number of explored branches (by default, pre-configured to avoid long running of Pex). Although we tried to set higher upper-bound values, Pex was still not able to generate unit tests that achieve higher coverage than the existing CUT. To address this issue, we performed a partial generalization by not promoting the loop bound as a parameter for the PUT. Due to our partial generalization, the transformed PUT achieved a branch coverage of 83\%, which is 11\% higher than the existing CUT.

For NUnit, the LOC of PUTs is more than the LOC of CUTs. The reason is that to transform $2$ CUTs to PUTs, the respective test objectives required \textit{specialized} test data, such as that a tree structure of keys was required to test the \CodeIn{ClearTestKey} method of the \CodeIn{NUnitRegistry} class. In order to create such specialized test data, we created the required test setup that increased the LOC of PUTs for NUnit.

We conducted our empirical study as third-party testers since we do not have the knowledge of the subject applications. We expect that our test-generalization results can be much better if the test generalization is performed by the developers of these subject applications. The reason is that developers can incorporate their domain knowledge during test generalization to write more effective PUTs.

%One of the major limitations of PUTs is that PUTs requires more effort from developers than writing conventional unit tests requires. Although PUTs reduce the complexity of writing multiple conventional unit tests with various concrete test inputs, developers need additional expertise in writing such PUTs as PUTs are more generic compared to conventional unit tests. For example, writing PUTs requires developers to prescribe a test oracle that can deal with the generality of test inputs. We show that to reduce the complexity of writing PUTs, we adopted a methodology of writing PUTs in two phases. In Phase 1, we generalized the existing conventional unit tests to PUTs using suggested test patterns. In Phase 2, we used supporting techniques to write more PUTs to assist Pex in generating high-covering tests. 

%In our study, we observed that we took longer time to write PUTs in Phase 2 compared to the time we took in Phase 1. In Phase 1, we transformed the existing conventional unit tests to PUTs and the existing unit tests assist in writing PUTs as shown in Section~\ref{sec:example} with an example. In Phase 2, we discovered the un-covered code portions and wrote more PUTs to assist Pex to generate tests to cover the un-covered code portions. Based on our experience, we believe that to enjoy the test effectiveness achieved by writing PUTs and to reduce the cost involved in writing PUTs, a practical solution could be retrofitting PUTs by transforming these conventional unit tests to PUTs. We expect that writing a single conventional unit test to test a method under test and then transforming it to a PUT can help developers in writing the PUTs. Such a single conventional unit test can act as an \textit{example} unit test representing the intention of ``what'' needs to be tested. We expect that this methodology can both ease the process of writing PUT and still achieve high test effectiveness in unit testing. 

%As shown in our study, although the usage of the suggested test patterns and the supporting techniques can reduce effort of developers in writing PUTs and allow the test generation tool to generate high-covering tests, the complexity lies in being able to use them. In general, developers might consider it a tougher job to learn the supporting techniques and use them to write PUTs than writing multiple possible conventional unit tests. Nevertheless, our study shows that PUTs are more effective than conventional unit tests in detecting defects and also in achieving high code coverage. Therefore, we believe that the choice of writing PUTs is a trade-off between cost and benefit.