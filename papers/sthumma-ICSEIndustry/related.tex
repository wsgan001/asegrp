\section{Related Work}
\label{sec:related}

Our approach is closely related to two major research areas: regression testing and method-call sequence generation.

\textbf{Regression testing.} There exist approaches~\cite{Elbaum:capture, orso:capture, david:java} that use a capture-and-replay strategy for generating regression tests. In the capture phase, these approaches monitor the methods called during program execution and uses these method calls in the replay phase to generate unit tests. Our approach also uses a strategy similar to the capture-and-replay strategy, where we capture dynamic traces during program execution and use those traces for generating regression tests. However, unlike existing approaches that replay exactly the same captured behavior, our approach replays beyond the captured behavior by using dynamic symbolic execution in generating new regression tests.

Another existing approach, called Orstra~\cite{xie06:augmenting}, augments an existing test suite with additional assertions to detect regression faults. To add these additional assertions, Orstra executes given test suite and collects the return values and receiver object states after the execution of methods under test. Orstra generates additional assertions based on the collected return values or receiver object states. Our approach also uses a similar strategy for generating assertions in the regression tests. However, unlike Orstra that requires an existing test suite as input, our approach does not require any inputs.

Another category of existing approaches~\cite{DeMillo91:constraint, taneja08:diffgen, evans07:differential} in regression testing primarily target at using regression tests for effectively exposing the behavioral differences between two versions of a software. For example, these approaches target at selecting those regression tests that are relevant to portions of the code changed between the two versions of software. However, all these approaches require an existing regression test suite, which is the primary objective of our current approach.

\textbf{Method-call sequence generation.} To test object-oriented programs, existing test-generation approaches~\cite{csallner:jcrasher, JTEST, pacheco:eclat, xie:rostra} accept a class under test and generate sequences of method calls randomly. These approaches generate random values for arguments of those method calls. Another set of approaches~\cite{inkumsah08:improving} replaces concrete values for method arguments with symbolic values and exploits dynamic symbolic execution techniques~\cite{Clarke:symbolic, godefroid:dart, king:symex, koushik:cute} to regenerate concrete values based on branching conditions in the method under test. However, all these approaches cannot handle multiple classes and their methods due to a large search space of possible sequences.

Randoop~\cite{pacheco:feedback} is a random testing approach that uses an incremental approach for constructing method-call sequences. Randoop randomly selects a method call and finds arguments required for these method calls. Randoop uses previously constructed method-call sequences to generate arguments for the newly selected method call. Unlike a pure random approach, Randoop incorporates feedback obtained from previously constructed method-call sequences while generating new test inputs. As soon as a method-call sequence is constructed, Randoop executes the sequence and verifies whether the sequence violates any contracts and filters. Randoop cannot effectively generate sequences that achieve high coverage of the code under test as Randoop still relies on random techniques~\cite{thummalapenta09:mseqgen}. In our previous approach~\cite{tillman:pexwhite}, we applied Pex on a core .NET component for detecting defects. Unlike our new approach that uses realistic scenarios recorded during program executions, our previous approach generates individual PUTs for each public method of all public classes. Therefore, our previous approach is not as effective as our new approach in generating tests that achieve a high coverage of the code under test, which is the primary focus of our new approach.

Our approach is also related to another category of approaches based on mining source code~\cite{Engler2001deviant, acharya06:mining, wasylkowski07:detecting, thummalapenta09:mseqgen}. These approaches statically analyze code bases and uses mining algorithms such as 
frequent itemset mining~\cite{wang:bide} or association rule mining~\cite{agarwal:association} for extracting frequent patterns. These frequent patterns are treated as programming rules in either assisting programmers while writing code or for detecting violations as deviations from these patterns. Unlike these existing approaches, our approach mines dynamic traces recorded during program executions and uses those traces for generating regression tests. Our previous work~\cite{thummalapenta09:mseqgen} also mines method-call sequences from existing code bases. Our previous work uses these method-call sequences to assist random or DSE-based approaches. Our new approach is significantly different from our previous work in two major aspects. First, our new approach is a complete approach for automatically generating regression tests from dynamic traces, whereas, our previous work mines method-call sequences to assist random or DSE-based approaches. Second, our new approach uses dynamic traces, which are more precise compared to the static traces used in our previous work.