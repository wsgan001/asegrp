
\section{Introduction}
\label{Introduction}

In software testing, test-adequacy criteria play an important role
in determining whether the software under test (SUT) is adequately
tested~\cite{Goodenough:75,Zhu:96}. With a test-adequacy criterion,
a tester can continually create new test cases until the suite of
test cases created so far satisfies the criterion. $Mutation$
$testing$, which was first proposed by Hamlet~\cite{Hamlet:77} and
DeMillo et al.~\cite{DeMillo:78}, is an intensively studied way to
construct such a test-adequacy criterion. In mutation testing, many
faulty versions (known as $mutants$) of the SUT are generated
through automatically changing the SUT with $mutation$ $operators$,
each of which is a rule to produce faulty versions and can be
applied to various statements. Since the first proposal, mutation
testing has attracted the attention of many researchers (e.g., Acree
et al.~\cite{Acree:79}, Budd et al.~\cite{Budd:80b}, Wong and
Mathur~\cite{Mathur:91,Wong:93,Wong:95}, Offutt et
al.~\cite{Offutt:92,Offutt:94,Offutt:96,Offutt:97,Offutt:99,Ma:05},
Mresa et al.~\cite{Mresa:99}, Hierons and Harman~\cite{Hierons:99},
Barbosa et al.~\cite{Barbosa:01}, and Zeller et
al.~\cite{Grun:09,Schuler:09}). Recently, researchers used mutation
operators to automatically produce faulty software to facilitate
experimentation in research of software
testing~\cite{Briand:04,Briand:06,Mayer:06,Tuya:07}. Andrews et
al.~\cite{Andrews:05} and Do et al.~\cite{Do:06} reported some
evidence that faults generated with mutation operators are similar
to real faults in evaluating test effectiveness. Following the
terminology of Andrews et al.~\cite{Andrews:05,SiamiNamin:08}, we
refer to this way of using mutation as $mutation$ $analysis$.

Mutation testing and mutation analysis are usually very
expensive~\cite{Budd:80b,Mathur:91,Wong:93,Offutt:96,SiamiNamin:08}.
For example, Proteum~\cite{Delamaro:96} generates 4,937 mutants for
$tcas$ (which is the smallest program among the Siemens
programs~\cite{Hutchins:94} and contains only 137 non-commenting and
non-whitespace lines of code) using 108 mutation operators. Thus,
compiling and executing a large number of mutants can be a big
burden in mutation testing and analysis. To alleviate this burden,
researchers have proposed various
techniques~\cite{Acree:79,Mathur:91,Wong:93,Wong:95,Offutt:96,Barbosa:01,SiamiNamin:08}
for selecting a subset of all the mutants. Naturally, researchers
want the set of selected mutants to be similar to the set of all
mutants. One simple technique is random mutant
selection~\cite{Acree:79,Wong:93,Wong:95}, in which, given a fixed
percentage number (denoted as $x$), $x\%$ mutants are randomly
selected. However, researchers seem to be more enthusiastic at
investigating operator-based mutant
selection~\cite{Mathur:91,Wong:93,Wong:95,Offutt:96,Barbosa:01,SiamiNamin:08},
which aims to select mutants generated with only a set of sufficient
mutation operators\footnote{A set of mutation operators are
sufficient if the mutants generated by the mutation operators can
very much represent the mutants generated by all the mutation
operators.}. While early research on operator-based mutant
selection~\cite{Wong:93,Wong:95,Offutt:96} tries to determine
sufficient mutation operators via simple rules, recent
research~\cite{Barbosa:01,SiamiNamin:08} relies on sophisticated
procedures to determine sufficient mutation operators involving
statistical information that can be acquired only through executing
a large number of mutants with a sufficiently large set of test
cases.

Despite the enthusiasm in investigating operator-based mutant
selection, whether operator-based mutant selection is superior to
random mutant selection for mutation testing remains an open
question. That is to say, despite recent progress in operator-based
mutant selection (e.g., Offutt et al.~\cite{Offutt:96}, Barbosa et
al.~\cite{Barbosa:01}, and Siami Namin et al.~\cite{SiamiNamin:08}),
there is lack of empirical evaluation of these operator-based
mutant-selection techniques against random mutant selection
techniques. Furthermore, as we can view random mutant selection as
an approach to mutant selection with average effectiveness,
answering the preceding open question can help us gain insights and
deep understanding to the current research and achievements on
mutant selection.

In this paper, we report an empirical study attempting to answer
this open question. To evaluate the effectiveness of each
mutant-selection technique, we adopt a widely used metric for
evaluating mutant-selection techniques. The metric aims to measure
to what extent the selected mutants are able to represent the
whole set of mutants. Furthermore, we also evaluate the stability
of each technique by checking how consistently the technique
performs under different circumstances. For either effectiveness
or stability, our empirical results do not support that
operator-based mutant selection is superior to random mutant
selection. That is to say, random mutant selection remains a
competitive or even better choice compared with recent progress in
operator-based mutant selection. Furthermore, as random mutant
selection selects mutants on the basis of individual mutants
instead of mutation operators, our empirical results also indicate
that mutant-selection techniques based on individual mutants
should be worthy of further investigation.

The main contributions of our study are as follows.


\begin{itemize}
\vspace{-2ex}

\item Our study empirically evaluates three recent operator-based
mutant-selection techniques (i.e., Offutt et al.~\cite{Offutt:96},
Barbosa et al.~\cite{Barbosa:01}, and Siami Namin et
al.~\cite{SiamiNamin:08}) against random mutant selection for
mutation testing.\vspace{-2ex}

\item Our study produces the first empirical results concerning
stability of operator-based mutant selection and random mutant
selection for mutation testing. \vspace{-2ex}

\item Beside the random technique studied previously (referred to as
the one-round random technique in this paper), our study also
investigates another random technique involving two steps to select
each mutant (referred to as the two-round random technique in this
paper).\vspace{-2ex}

\item The subjects used in our study are larger than those used in
previous studies of random mutant selection. To the best of our
knowledge, due to the extreme expensiveness of experimenting
mutant-selection techniques, the Siemens programs are by far the
largest subjects\footnote{Some studies on mutation testing and
analysis (such as Do et al.~\cite{Do:06}) do use larger subjects,
but they do not focus on mutant selection and they do not consider
all the generated mutants.} used in studies of mutant
selection~\cite{SiamiNamin:08}. \vspace{-2ex}

\end{itemize}

We organize the rest of this paper as follows.
Section~\ref{Experiment} presents the experimental design in our
study. Section~\ref{Results} presents and analyzes the results
obtained from our experiments. Section~\ref{Discussion} discusses
other issues in our study. Section~\ref{RelatedWork} discusses
related work. Section~\ref{Conclusion} concludes and presents some
future work.
